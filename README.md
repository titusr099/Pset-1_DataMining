AnÃ¡lisis de Compras en Instacart

DescripciÃ³n del Proyecto:

Este proyecto realiza un anÃ¡lisis detallado de los patrones de compra en Instacart utilizando Snowflake y MageAI. Se implementÃ³ un modelo estrella (Star Schema) para estructurar los datos, permitiendo insights accionables sobre el comportamiento de los clientes.

DEBER01_DATAM/

â”‚â”€â”€ data/                     # Datos sin procesar y finales

â”‚â”€â”€ data_pipeline/            # Pipelines de transformaciÃ³n de datos

â”‚   â”‚â”€â”€ custom/               # TransformaciÃ³n de datos y modelo estrella (GOLD Schema)

â”‚   â”‚â”€â”€ data_loaders/         # Scripts para extracciÃ³n y carga de datos

â”‚â”€â”€ docs/                     # Reportes y documentaciÃ³n

â”‚â”€â”€ notebooks/                # Jupyter Notebooks con anÃ¡lisis exploratorio y visualizaciones

â”‚â”€â”€ scripts/                  # Scripts para conexiÃ³n y pruebas con Snowflake

â”‚â”€â”€ README.md                 # DocumentaciÃ³n principal del proyecto

â”‚â”€â”€ requirements.txt          # Dependencias necesarias para ejecutar el proyecto



CÃ³mo Ejecutar el Proyecto:

1. ConfiguraciÃ³n Inicial

AsegÃºrate de tener las siguientes variables de entorno configuradas en tu archivo .env o en tu sistema:
ğŸ”¹ ConfiguraciÃ³n de Snowflake

SNOWFLAKE_ACCOUNT=<TU_CUENTA>

SNOWFLAKE_USER=<TU_USUARIO>

SNOWFLAKE_PASSWORD=<TU_CONTRASEÃ‘A>

SNOWFLAKE_WAREHOUSE=<TU_WAREHOUSE>

SNOWFLAKE_DATABASE=<TU_DB>

SNOWFLAKE_SCHEMA=<ESQUEMA>


ğŸ”¹ ConfiguraciÃ³n de MySQL

MYSQL_HOST=<TU_HOST>

MYSQL_PORT=<TU_PUERTO>

MYSQL_DATABASE=<TU_DB>

MYSQL_USER=<TU_USUARIO>

MYSQL_PASSWORD=<TU_CONTRASEÃ‘A>




2. Instalar dependencias
Ejecuta el siguiente comando para instalar todas las dependencias necesarias:

pip install -r requirements.txt


3. EjecuciÃ³n del Pipeline de Datos

Para gestionar el pipeline de datos, se utilizÃ³ Mage.AI. Puedes encontrar mÃ¡s detalles en su documentaciÃ³n oficial.
https://docs.mage.ai/introduction/overview

- ExtracciÃ³n de Datos desde MySQL

La extracciÃ³n de datos se realiza desde una base de datos MySQL local.
El script correspondiente se encuentra en:
data_pipeline/data_loaders/extract_data.py

- Carga de Datos en Snowflake

Una vez extraÃ­dos, los datos se cargan en Snowflake utilizando el siguiente script:
data_pipeline/data_loaders/load_data.py

- TransformaciÃ³n y Limpieza de Datos

Los datos extraÃ­dos son transformados y normalizados antes de ser almacenados en Snowflake.
ğŸ“‚ data_pipeline/custom/raw_to_clean_snowflake.py

AquÃ­, los datos se migran del esquema RAW al CLEAN, asegurando calidad y consistencia.

ğŸ”¹ CreaciÃ³n del Modelo Estrella

El modelo estrella se construye en el siguiente archivo:
data_pipeline/custom/start_model_dimensional.py

Esto permite estructurar los datos de forma optimizada para responder preguntas clave de negocio.

4. AnÃ¡lisis e Insights

Este proyecto responde preguntas clave sobre el comportamiento de compra en Instacart, incluyendo:

âœ”ï¸ Â¿QuÃ© dÃ­as y horas tienen mÃ¡s compras?

âœ”ï¸ Â¿CuÃ¡les son los productos mÃ¡s comprados y reordenados?

âœ”ï¸ Â¿CuÃ¡ntos productos se compran en promedio por orden?

âœ”ï¸ Â¿CÃ³mo varÃ­a el comportamiento de compra segÃºn el dÃ­a y la hora?


Los resultados estÃ¡n documentados en analysis.ipynb, con grÃ¡ficos y tablas generadas.